{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41766c29-f730-4821-ab69-212548c9d4f9",
   "metadata": {},
   "source": [
    "# NFL Database Project: WebScraping & Data Cleaning\n",
    "<br>\n",
    "CIS 761 Database Management Systems â€“ Term Project<br>\n",
    "Kansas State University\n",
    "<br><br>\n",
    "Vishnu Bondalakunta<br>\n",
    "Charles Zumbaugh<br>\n",
    "James Chapman<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed33903-f986-4275-b4f9-1ab3a9c9af14",
   "metadata": {},
   "source": [
    "#### This notebook uses the public ESPN API. The URLs and endpoints were found in the following GitHub link. ESPN does not provide official documentation.\n",
    "\n",
    "* ## [List of NFL API Endpoints](https://gist.github.com/nntrn/ee26cb2a0716de0947a0a4e9a157bc1c#event-competitions-api)\n",
    "\n",
    "#### 10 tables are collected and saved as CSV files, which is used to populate the NFL database.\n",
    "* games\n",
    "* season_dates\n",
    "* venues\n",
    "* teams\n",
    "* linescores\n",
    "* rosters\n",
    "* positions\n",
    "* athletes\n",
    "* plays\n",
    "* player_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbb51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101ec647-e2b6-4552-931b-5981135229a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2013,2024) # ! Keep track of calendar year and NFL season year\n",
    "\n",
    "ESPN_EVENTS = 'https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?limit=1000&dates={}' #.format(year)\n",
    "ESPN_ROSTERS = 'https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/{}/competitions/{}/competitors/{}/roster' #.format(game_id,game_id,team_id)\n",
    "ESPN_ATHLETE_INFO = 'https://site.web.api.espn.com/apis/common/v3/sports/football/nfl/athletes/{}' #.format(player_id)\n",
    "ESPN_VENUE_INFO = 'http://sports.core.api.espn.com/v2/sports/football/leagues/nfl/venues/{}' #.format(venue_id)\n",
    "ESPN_TEAM_INFO = 'https://site.api.espn.com/apis/site/v2/sports/football/nfl/teams/{}' #.format(team_id)\n",
    "ESPN_POSITION_INFO = 'http://sports.core.api.espn.com/v2/sports/football/leagues/nfl/positions/{}' #.format(position_id)\n",
    "ESPN_PLAY_BY_PLAY = 'https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/{}/competitions/{}/plays?limit=300' #.format(game_id,game_id)\n",
    "ESPN_STATISTICS = 'https://sports.core.api.espn.com/v2/sports/football/leagues/nfl/events/{}/competitions/{}/competitors/{}/roster/{}/statistics/0' #.format(game_id,game_id,team_id,player_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33829d6-bc7a-4f17-8c01-a5ddc19701ec",
   "metadata": {},
   "source": [
    "# Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300ee171-270d-47ee-a8f5-2f8556604e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2976 entries, 0 to 3584\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   game_id       2976 non-null   int64 \n",
      " 1   date          2976 non-null   object\n",
      " 2   attendance    2976 non-null   int64 \n",
      " 3   venue_id      2976 non-null   int64 \n",
      " 4   home_team_id  2976 non-null   int64 \n",
      " 5   away_team_id  2976 non-null   int64 \n",
      " 6   utc_time      2976 non-null   object\n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 186.0+ KB\n"
     ]
    }
   ],
   "source": [
    "games = pd.DataFrame()\n",
    "for year in years:\n",
    "    try:\n",
    "        events = requests.get(ESPN_EVENTS.format(year)).json()\n",
    "        yearlyEvents = pd.json_normalize(events['events'])\n",
    "        games = pd.concat([games, yearlyEvents], ignore_index=True)\n",
    "    except: \n",
    "        print(year)\n",
    "\n",
    "# games['competitions'] is a list of dictionaries \n",
    "games['attendance'] = games['competitions'].apply(lambda x : x[0]['attendance']).astype('int64')\n",
    "games['venue_id'] = games['competitions'].apply(lambda x : x[0]['venue']['id']).astype('int64')\n",
    "\n",
    "# games['competitions'][0]['competitors'] is a list of 2 dictionaries (home and away).\n",
    "games['competitors'] = games['competitions'].apply(lambda x : x[0]['competitors'])\n",
    "\n",
    "games['home_team_id'] = games['competitors'].apply(lambda x : x[0]['id']).astype('int64')\n",
    "games['away_team_id'] = games['competitors'].apply(lambda x : x[1]['id']).astype('int64')\n",
    "\n",
    "# Drop pre-season, off-season, & probowl\n",
    "games = games.drop(games[(games['season.type'].isin([1, 4]))].index)\n",
    "games = games.drop(games[(games['home_team_id'].isin([31,32,35,36]))].index)\n",
    "\n",
    "# Split datetime into date/time \n",
    "# decompose date/week/season year/season type\n",
    "games['datetime'] = pd.to_datetime(games['date'])\n",
    "games['utc_time'] = games['datetime'].dt.strftime(\"%H:%M\")\n",
    "games['date'] = games['datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "season_dates = games[['date','season.year','season.type','week.number']].copy()\n",
    "\n",
    "#Keep around For linescores\n",
    "gameLinescores = games[['id','competitors']].copy()\n",
    "\n",
    "# Drop rows\n",
    "games = games.rename(columns={'id':'game_id'})\n",
    "games = games[['game_id',\n",
    "               'date',\n",
    "               'attendance',\n",
    "               'venue_id',\n",
    "               'home_team_id',\n",
    "               'away_team_id',\n",
    "               'utc_time']] \n",
    "games['game_id'] = games['game_id'].astype('int64')\n",
    "games.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077d0a9-3fac-4cab-8cd0-4200bb8dcd96",
   "metadata": {},
   "source": [
    "# Season_Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66dc44ba-1976-4330-b14e-ce8bfa6b4c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 827 entries, 0 to 3584\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         827 non-null    object\n",
      " 1   season_year  827 non-null    int64 \n",
      " 2   season_type  827 non-null    object\n",
      " 3   week         827 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 32.3+ KB\n"
     ]
    }
   ],
   "source": [
    "season_dates = season_dates.rename(columns={'season.year':'season_year',\n",
    "                                          'season.type':'season_type',\n",
    "                                          'week.number':'week'})\n",
    "# season_types names\n",
    "season_dates.loc[(season_dates['season_type']== 2),'season_type'] = 'Regular Season'\n",
    "season_dates.loc[(season_dates['season_type']== 3),'season_type'] = 'Post Season'\n",
    "\n",
    "season_dates.drop_duplicates(inplace=True)\n",
    "season_dates.info(verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fcc6c0-97ed-49bc-be98-884e1e5afa51",
   "metadata": {},
   "source": [
    "# Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817625aa-8ee6-4bd0-8ed4-0a0e30281acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   venue_id    46 non-null     int64 \n",
      " 1   venue_name  46 non-null     object\n",
      " 2   grass       46 non-null     bool  \n",
      " 3   indoor      46 non-null     bool  \n",
      " 4   city        46 non-null     object\n",
      " 5   state       40 non-null     object\n",
      " 6   capacity    46 non-null     int64 \n",
      "dtypes: bool(2), int64(2), object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "venues = pd.DataFrame()\n",
    "for venue_id in pd.unique(games['venue_id']):\n",
    "    try:\n",
    "        venue_info = requests.get(ESPN_VENUE_INFO.format(venue_id)).json()\n",
    "        venue_info = pd.json_normalize(venue_info)\n",
    "        venues = pd.concat([venues, venue_info], ignore_index=True)\n",
    "    except: \n",
    "        print(venue_id)\n",
    "\n",
    "# # Drop rows\n",
    "venues = venues[['id',\n",
    "                 'fullName',\n",
    "                 'grass',\n",
    "                 'indoor',\n",
    "                 'address.city',\n",
    "                 'address.state']]\n",
    "venues = venues.rename(columns={'id':'venue_id',\n",
    "                                'fullName':'venue_name',\n",
    "                                'address.city':'city',\n",
    "                                'address.state':'state'})\n",
    "\n",
    "venues['capacity'] = 0\n",
    "venues[['venue_id','capacity']] = venues[['venue_id','capacity']].astype('int64')\n",
    "venues.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c231af-b721-4b97-a9bb-2f05a03aa7e6",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57666c97-de78-4ad7-a90a-8a6087f25d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   team_id          32 non-null     int64 \n",
      " 1   location         32 non-null     object\n",
      " 2   team_name        32 non-null     object\n",
      " 3   abbreviation     32 non-null     object\n",
      " 4   venue_id         32 non-null     int64 \n",
      " 5   primary_color    32 non-null     object\n",
      " 6   secondary_color  32 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "teams = pd.DataFrame()\n",
    "for team_id in pd.unique(games['home_team_id']):\n",
    "    try:\n",
    "        team_info = requests.get(ESPN_TEAM_INFO.format(team_id)).json()\n",
    "        team_info = pd.json_normalize(team_info)\n",
    "        teams = pd.concat([teams, team_info], ignore_index=True)\n",
    "    except: \n",
    "        print(team_id)\n",
    "\n",
    "# # Drop rows\n",
    "teams = teams[['team.id',\n",
    "                 'team.location',\n",
    "                 'team.name',\n",
    "                 'team.abbreviation',\n",
    "                 'team.franchise.venue.id',\n",
    "                 'team.color',\n",
    "                 'team.alternateColor']]\n",
    "teams = teams.rename(columns={'team.id':'team_id',\n",
    "                             'team.location':'location',\n",
    "                             'team.name':'team_name',\n",
    "                             'team.abbreviation':'abbreviation',\n",
    "                             'team.franchise.venue.id':'venue_id',\n",
    "                             'team.color':'primary_color',\n",
    "                             'team.alternateColor':'secondary_color'})\n",
    "teams[['team_id','venue_id']] = teams[['team_id','venue_id']].astype('int64')\n",
    "teams.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660bfc1-975e-440e-b08c-2908268641d6",
   "metadata": {},
   "source": [
    "# Linescores \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d523ce5-425a-4bad-93b3-0756bbf664db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game canceled- 400554331\n",
      "Game canceled- 400951581\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24140 entries, 0 to 24139\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   game_id  24140 non-null  int64\n",
      " 1   team_id  24140 non-null  int64\n",
      " 2   quarter  24140 non-null  int64\n",
      " 3   score    24140 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 943.0 KB\n"
     ]
    }
   ],
   "source": [
    "linescores = pd.DataFrame(columns = [\"game_id\",\"team_id\",\"quarter\",\"score\"])\n",
    "overtimecount = 0\n",
    "def eachrow(game):\n",
    "    try:\n",
    "        for competitor in game['competitors']: # competitors[0] = home team\n",
    "            quarter = 0\n",
    "            for linescore in competitor['linescores']:\n",
    "                quarter += 1\n",
    "                linescores.loc[len(linescores.index)] = [game['id'], \n",
    "                                                         competitor['id'],\n",
    "                                                         quarter, \n",
    "                                                         linescore['value']]\n",
    "    except:\n",
    "        print('Game canceled-', game['id'])\n",
    "\n",
    "junk = gameLinescores.apply(eachrow, axis=1)\n",
    "\n",
    "linescores[['game_id','team_id','score']] = linescores[['game_id','team_id','score']].astype('int64')\n",
    "linescores.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37424e6-1098-4a4a-ad57-410fffbbb5b5",
   "metadata": {},
   "source": [
    "# Rosters \n",
    "\n",
    "The rosters URL lists all players under 'entries'. But the position is something like thisâ€¦<br>\n",
    "$ref : \"http://sports.core.api.espn.com/v2/sports/football/leagues/nfl/positions/46?lang=en&region=us\" <br>\r\n",
    "This just splits the link at \"positions\" giving \"/46?lang=en&region=us\"\n",
    "and then takes only numbers \"46\"\n",
    "\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74d2d41-08c2-471d-bf39-f0673e253556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game canceled or Pro bowl - 400554331\n",
      "Game canceled or Pro bowl - 400874729\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363404 entries, 0 to 363403\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   game_id      363404 non-null  int64  \n",
      " 1   team_id      363404 non-null  int64  \n",
      " 2   athlete_id   363404 non-null  int64  \n",
      " 3   position_id  363404 non-null  int64  \n",
      " 4   played       363404 non-null  boolean\n",
      "dtypes: boolean(1), int64(4)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "rosters = pd.DataFrame(columns = [\"game_id\", \"team_id\", \"athlete_id\",\"position_id\",\"didNotPlay\"])\n",
    "def eachrow(game):\n",
    "    temp_game_id = game['game_id']\n",
    "    temp_home_team_id = game['home_team_id']\n",
    "    temp_away_team_id = game['away_team_id']\n",
    "\n",
    "    try:\n",
    "        homeRoster = requests.get(ESPN_ROSTERS.format(temp_game_id,temp_game_id,temp_home_team_id)).json()\n",
    "        for player in homeRoster['entries']:\n",
    "            # position_id = re.search(r'(?<=positions/)[0-9]+(?=\\?)', player['position']['$ref']).group(0)\n",
    "            split = re.split(\"positions\", player['position']['$ref'])\n",
    "            position_id = re.sub(\"[^0-9.]\", \"\", split[1])\n",
    "            rosters.loc[len(rosters.index)] = [temp_game_id, \n",
    "                                                temp_home_team_id,\n",
    "                                                player['playerId'], \n",
    "                                                position_id, \n",
    "                                                player['didNotPlay']]\n",
    "    \n",
    "        awayRoster = requests.get(ESPN_ROSTERS.format(temp_game_id,temp_game_id,temp_away_team_id)).json()\n",
    "        # print(temp_game_id, temp_home_team_id, temp_away_team_id, len(homeRoster['entries']), len(awayRoster['entries']))\n",
    "        for player in awayRoster['entries']:\n",
    "            split = re.split(\"positions\", player['position']['$ref'])\n",
    "            position_id = re.sub(\"[^0-9.]\", \"\", split[1])\n",
    "            rosters.loc[len(rosters.index)] = [temp_game_id, \n",
    "                                                temp_home_team_id,\n",
    "                                                player['playerId'], \n",
    "                                                position_id, \n",
    "                                                player['didNotPlay']]\n",
    "    except:\n",
    "        print('Game canceled or Pro bowl -', game['game_id'])\n",
    "\n",
    "games.apply(eachrow, axis=1)\n",
    "\n",
    "rosters[['game_id','team_id','athlete_id','position_id']] = rosters[['game_id','team_id','athlete_id','position_id']].astype('int64')\n",
    "rosters['played'] = ~rosters['didNotPlay'].astype('boolean')\n",
    "rosters = rosters.drop(['didNotPlay'], axis=1)\n",
    "rosters.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0be8e-dfcf-4e34-b7d6-5f9d413158d9",
   "metadata": {},
   "source": [
    "# Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3bccf3e-e673-4536-bed6-e40c99ddc734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   position_id    24 non-null     int64 \n",
      " 1   position_name  24 non-null     object\n",
      " 2   abbreviation   24 non-null     object\n",
      " 3   platoon        24 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 896.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "positions = pd.DataFrame()\n",
    "for position_id in pd.unique(rosters['position_id']):\n",
    "    try:\n",
    "        position_info = requests.get(ESPN_POSITION_INFO.format(position_id)).json()\n",
    "        position_info = pd.json_normalize(position_info)\n",
    "        positions = pd.concat([positions, position_info], ignore_index=True)\n",
    "    except: \n",
    "        print(position_info)\n",
    "\n",
    "def eachrow(x):\n",
    "    try:\n",
    "        for competitor in game['competitors']: # competitors[0] = home team\n",
    "            quarter = 0\n",
    "            for linescore in competitor['linescores']:\n",
    "                quarter += 1\n",
    "                linescores.loc[len(linescores.index)] = [game['id'], \n",
    "                                                         competitor['id'],\n",
    "                                                         quarter, \n",
    "                                                         linescore['value']]\n",
    "    except:\n",
    "        print('Game canceled-', game['id'])\n",
    "\n",
    "# Drop rows\n",
    "positions = positions[['id', 'name', 'abbreviation']]\n",
    "positions['platoon'] = ''\n",
    "positions = positions.rename(columns={'id':'position_id','name':'position_name'})\n",
    "positions['position_id'] = positions['position_id'].astype('int64')\n",
    "positions.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b825c8b-b46b-426c-939c-1a3a45c932f8",
   "metadata": {},
   "source": [
    "# Athletes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513d029-d539-41bc-a13f-04fce56e70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(4568981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a6ba98-f344-4ed3-bec8-57406f10c342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568981\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7166 entries, 0 to 7165\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   athlete_id   7166 non-null   object\n",
      " 1   firstName    7166 non-null   object\n",
      " 2   lastName     7166 non-null   object\n",
      " 3   birth_city   7166 non-null   object\n",
      " 4   birth_state  7166 non-null   object\n",
      " 5   jersey       6650 non-null   object\n",
      " 6   height       7158 non-null   object\n",
      " 7   weight       7158 non-null   object\n",
      " 8   dob          7121 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 504.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_29924\\3609424312.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  athletes['birth_city'] = athletes['displayBirthPlace'].apply(lambda x: split_birthplace(x, 0))\n",
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_29924\\3609424312.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  athletes['birth_state'] = athletes['displayBirthPlace'].apply(lambda x: split_birthplace(x, 1))\n"
     ]
    }
   ],
   "source": [
    "athletes = pd.DataFrame()\n",
    "for athlete_id in pd.unique(rosters['athlete_id']):\n",
    "    try:\n",
    "        athlete_info = requests.get(ESPN_ATHLETE_INFO.format(athlete_id)).json()\n",
    "        athlete_info = pd.json_normalize(athlete_info['athlete'])\n",
    "        athletes = pd.concat([athletes, athlete_info], ignore_index=True)\n",
    "    except: \n",
    "        print(athlete_id)\n",
    "\n",
    "def split_birthplace(s: str, index: int):\n",
    "    try:\n",
    "        val = s.split(', ')[index]\n",
    "        return val\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "athletes['birth_city'] = athletes['displayBirthPlace'].apply(lambda x: split_birthplace(x, 0))\n",
    "athletes['birth_state'] = athletes['displayBirthPlace'].apply(lambda x: split_birthplace(x, 1))\n",
    "\n",
    "# Drop rows\n",
    "athletes = athletes.rename(columns={'id':'athlete_id',\n",
    "                                     'displayHeight':'height',\n",
    "                                     'displayWeight':'weight',\n",
    "                                     'displayDOB':'dob'})#'displayDraft':'drafted_bool',\n",
    "athletes = athletes[['athlete_id',\n",
    "                     'firstName',\n",
    "                     'lastName',\n",
    "                     'birth_city',\n",
    "                     'birth_state',\n",
    "                     'jersey',\n",
    "                     'height',\n",
    "                     'weight',\n",
    "                     'dob']]\n",
    "                     #'drafted_bool',#'debutYear',#'displayDraft']]#'college.id',\n",
    "                     #'jersey',#'displayJersey',#'displayExperience',#'position.id',\n",
    "                     #'team.id',#'collegeTeam.id',#'collegeAthlete.id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e15c4a-7903-4c31-9521-c6292af61ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59af6ce-102c-4019-9bf1-b60273291930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(s: str) -> str:\n",
    "    try:\n",
    "        return re.match(r'[0-9]+', s).group(0)\n",
    "    except:\n",
    "        return pd.NA #'NULL'\n",
    "\n",
    "\n",
    "def get_height_inches(height_str: str) -> int:\n",
    "    # pattern of display height in [0-9]'[0-9]+\" where the first\n",
    "    # value is height in feet and the second is height in inches.\n",
    "    try:\n",
    "        matches = re.findall(r'[0-9]+', height_str)\n",
    "        feet = matches[0]\n",
    "        inches = matches[1]\n",
    "        return int(feet) * 12 + int(inches)\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "def clean_date(date_string: str) -> str:\n",
    "    # The date is formatted in one of several ways:\n",
    "    # %M-%d-%Y\n",
    "    # %M-%d-%y\n",
    "    # %m-%d-%Y\n",
    "    # %m-%d-%y\n",
    "    try:\n",
    "        date_values = re.findall(r'[0-9]+', date_string)\n",
    "        day = date_values[0]\n",
    "        month = date_values[1]\n",
    "        year = date_values[2]\n",
    "        day = '0' + day if len(day) < 2 else day\n",
    "        month = '0' + month if len(month) < 2 else month\n",
    "        if len(year) < 4:\n",
    "            if int(year) > 24:\n",
    "                year = '19' + year\n",
    "            else:\n",
    "                year = '20' + year\n",
    "        return f'{month}-{day}-{year}'\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "athletes['weight'] = athletes['weight'].apply(extract_number)\n",
    "athletes['height'] = athletes['height'].apply(get_height_inches)\n",
    "athletes['dob'] = athletes['dob'].apply(clean_date)\n",
    "athletes.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddb09d-ef54-4422-b63c-918266b92f99",
   "metadata": {},
   "source": [
    "# Replace IDs with names\n",
    "For Database Normalization. <br>\n",
    "* venue_id --> venue_name\n",
    "* team_id --> team_name\n",
    "* position_id --> position_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7350a8-9cb0-45f1-adc7-998532b957c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games table - venue_id, home_team_id, & away_team_id\n",
    "games = games.merge(venues[['venue_id','venue_name']],how=\"left\",on = ['venue_id'])\n",
    "games = games.merge(teams[['team_id','team_name']],how=\"left\", left_on = ['home_team_id'],right_on = ['team_id'])\n",
    "games = games.rename(columns={'team_name':'home_team_name'})\n",
    "games = games.drop(['team_id'], axis=1)\n",
    "\n",
    "# away_team_id\n",
    "games = games.merge(teams[['team_id','team_name']],how=\"left\", left_on = ['away_team_id'],right_on = ['team_id'])\n",
    "games = games.rename(columns={'team_name':'away_team_name'})\n",
    "games = games.drop(['venue_id','away_team_id','home_team_id','team_id'], axis=1)\n",
    "\n",
    "# teams table - venue_id\n",
    "teams = teams.merge(venues[['venue_id','venue_name']],how=\"left\",on = ['venue_id'])\n",
    "teams = teams.drop(['venue_id'], axis=1)\n",
    "\n",
    "# linescores table - team_id\n",
    "linescores = linescores.merge(teams[['team_id','team_name']],how=\"left\",on = ['team_id'])\n",
    "linescores = linescores.drop(['team_id'], axis=1)\n",
    "\n",
    "# rosters table - team_id & position_id\n",
    "rosters = rosters.merge(teams[['team_id','team_name']],how=\"left\",on = ['team_id'])\n",
    "rosters = rosters.merge(positions[['position_id','position_name']],how=\"left\",on = ['position_id'])\n",
    "rosters = rosters.drop(['team_id','position_id'], axis=1)\n",
    "rosters = rosters.drop(rosters[(rosters['athlete_id'].isin([4568981,2514468,17372,11717]))].index)\n",
    "rosters.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop ID columns from original tables\n",
    "teams = teams.drop(['team_id'], axis=1)\n",
    "venues = venues.drop(['venue_id'], axis=1)\n",
    "positions = positions.drop(['position_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b2fed4-8375-4233-8710-9b60b17edfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Johnson 04-02-1987\n",
      "--Change all athlete_id= 13279 to 2219984\n",
      "Tom Johnson 08-30-1984\n",
      "--Change all athlete_id= 10001 to 16695\n",
      "Willie Smith 11-13-1986\n",
      "--Change all athlete_id= 14447 to 2219931\n",
      "Branden Albert 11-04-1984\n",
      "--Change all athlete_id= 11249 to 3938599\n",
      "Chris Manhertz 04-10-1992\n",
      "--Change all athlete_id= 2531358 to 4071345\n",
      "Brandon Scherff 12-26-1991\n",
      "--Change all athlete_id= 2511708 to 4287933\n",
      "De'Angelo Henderson 11-24-1992\n",
      "--Change all athlete_id= 2968226 to 2565755\n"
     ]
    }
   ],
   "source": [
    "athletesDUPLICATES = athletes[athletes.duplicated(keep='first', subset=['firstName','lastName','dob'])][['firstName','lastName','dob']].copy()\n",
    "for row in athletesDUPLICATES[athletesDUPLICATES['lastName'] != 'Team'].to_numpy():\n",
    "    IdS = (athletes.loc[(athletes['firstName']==row[0])& (athletes['lastName']==row[1])& (athletes['dob']==row[2])]['athlete_id']).dropna().unique()\n",
    "    print(row[0],row[1],row[2])\n",
    "    print('--Change all athlete_id=',IdS[0],'to',IdS[1])\n",
    "    rosters.loc[(rosters['athlete_id']==IdS[0]),'athlete_id']= IdS[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f29ef-68e5-424d-95ee-b22683a91828",
   "metadata": {},
   "source": [
    "# Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0df4e7-4c1b-4b3e-9aa4-51f5694af69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522707 entries, 0 to 522706\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   play_id            522707 non-null  object\n",
      " 1   start_down         522707 non-null  int64 \n",
      " 2   end_down           522707 non-null  int64 \n",
      " 3   quarter            522707 non-null  int64 \n",
      " 4   play_type          522691 non-null  object\n",
      " 5   seconds_remaining  522707 non-null  int64 \n",
      " 6   score_value        522707 non-null  int64 \n",
      " 7   yards              522707 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 31.9+ MB\n"
     ]
    }
   ],
   "source": [
    "plays = pd.DataFrame()\n",
    "player_plays = pd.DataFrame(columns = ['game_id','play_id','type',\"player_id\"])\n",
    "\n",
    "# ignore Plays column that we don't use has a data type conversion\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for game_id in games['game_id']:\n",
    "    try:\n",
    "        game_data = requests.get(ESPN_PLAY_BY_PLAY.format(game_id,game_id)).json()\n",
    "        play_data = pd.json_normalize(game_data['items'])\n",
    "        play_data['game_id'] = game_id\n",
    "        plays = pd.concat([plays, play_data], ignore_index=True)\n",
    "    except: \n",
    "        print(game_id)\n",
    "\n",
    "plays = plays.rename(columns={'id':'play_id',\n",
    "                             'type.text':'play_type',\n",
    "                             'period.number':'quarter',\n",
    "                             'clock.value':'seconds_remaining',\n",
    "                              'scoreValue':'score_value',\n",
    "                              'statYardage':'yards',\n",
    "                              'start.down':'start_down',\n",
    "                             'end.down':'end_down'})\n",
    "\n",
    "temp = plays[['game_id','play_id','participants']].copy()\n",
    "\n",
    "plays = plays[['play_id',\n",
    "               'start_down',\n",
    "               'end_down',\n",
    "               'quarter',\n",
    "               'play_type',\n",
    "               'seconds_remaining',\n",
    "               'score_value',\n",
    "               'yards']] \n",
    "\n",
    "plays['start_down'] = plays['start_down'].apply(lambda x: x if x >= 0 else 0)\n",
    "plays['end_down'] = plays['end_down'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "plays[['start_down', 'end_down', 'quarter', \n",
    "       'seconds_remaining', 'score_value', 'yards']] = plays[['start_down', 'end_down', 'quarter', \n",
    "                                                              'seconds_remaining', 'score_value', 'yards']].astype('int64')\n",
    "plays.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e67ce-e625-4313-8bf5-48417237f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eachrow(play):\n",
    "    try:\n",
    "        for player in play['participants']: \n",
    "            player_url = player['athlete']['$ref']\n",
    "            player_id = re.search(r'(?<=athletes/)[0-9]+(?=\\?)', player_url).group(0)\n",
    "            player_plays.loc[len(player_plays.index)] = [play['game_id'], \n",
    "                                                       play['play_id'],\n",
    "                                                       player['type'], \n",
    "                                                       player_id]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "junk = temp.apply(eachrow, axis=1)\n",
    "\n",
    "player_plays.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3104bf4-8e75-43f8-a798-8a5626316a7f",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb1a20-da79-4113-8093-e518ef399a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.info(verbose=True)\n",
    "for column in games.columns.tolist():\n",
    "    print(column,'--------',pd.unique(games[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad760992-07fe-4ab6-b100-d443c7cf0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dates.info(verbose=True)\n",
    "for column in season_dates.columns.tolist():\n",
    "    print(column,'--------',pd.unique(season_dates[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409af73c-c09f-4cc5-b9a1-c8276443aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "linescores.info(verbose=True)\n",
    "for column in linescores.columns.tolist():\n",
    "    print(column,'--------',pd.unique(linescores[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bde349-bddf-46aa-b6fd-f0e6860ae303",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosters.info(verbose=True)\n",
    "for column in rosters.columns.tolist():\n",
    "    print(column,'--------',pd.unique(rosters[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fc53b-fce5-4ec4-88df-e9c79d5115e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes.info(verbose=True)\n",
    "for column in athletes.columns.tolist():\n",
    "    print(column,'--------',pd.unique(athletes[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da8e4a-e0fa-4926-91fa-9c0f1c21f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "venues.info(verbose=True)\n",
    "for column in venues.columns.tolist():\n",
    "    print(column,'--------',pd.unique(venues[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a1f24-c96d-42f9-a582-aa32aa8f45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.info(verbose=True)\n",
    "for column in teams.columns.tolist():\n",
    "    print(column,'--------',pd.unique(teams[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ecbb3-07b0-4431-bf07-375ab7618b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions.info(verbose=True)\n",
    "for column in positions.columns.tolist():\n",
    "    print(column,'--------',pd.unique(positions[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ebbc0-7354-4dc3-af19-118ab335cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays.info(verbose=True)\n",
    "for column in plays.columns.tolist():\n",
    "    print(column,'--------',pd.unique(plays[column]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158dca6-10a3-4fb2-a3ab-039d07ebcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_plays.info(verbose=True)\n",
    "for column in player_plays.columns.tolist():\n",
    "    print(column,'--------',pd.unique(player_plays[column]).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6300ecc-d300-4ab8-802c-1e4c7aaeb718",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fe76e-897d-43c4-a67d-5d7cae861ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "games.to_csv('games.csv', index=False)\n",
    "season_dates.to_csv('season_dates.csv', index=False)\n",
    "linescores.to_csv('linescores.csv', index=False)\n",
    "rosters.to_csv('rosters.csv', index=False)\n",
    "athletes.to_csv('athletes.csv', index=False)\n",
    "venues.to_csv('venues.csv', index=False)\n",
    "teams.to_csv('teams.csv', index=False)\n",
    "positions.to_csv('positions.csv', index=False)\n",
    "plays.to_csv('plays.csv', index=False)\n",
    "player_plays.to_csv('player_plays.csv', index=False)\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a93b7-3736-4922-b8d3-3ea8441a67b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b339bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    ": )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
